from optimum.onnxruntime import ORTModelForSeq2SeqLM
import streamlit as st
import torch
from transformers import AutoTokenizer, pipeline

torch.classes.__path__ = []

def summarize_article(input_text):
    MODEL_PATH = "model/mt5_onnx"

    # ONNXãƒ¢ãƒ‡ãƒ«ã®èª­ã¿è¾¼ã¿
    tokenizer = AutoTokenizer.from_pretrained(MODEL_PATH, local_files_only=True)
    model = ORTModelForSeq2SeqLM.from_pretrained(MODEL_PATH, local_files_only=True)

    summarizer = pipeline(
        "summarization",
        model=model,
        tokenizer=tokenizer
    )
    return summarizer(
        input_text,
        max_length=600,
        min_length=200,
        do_sample=True,
        temperature=0.5,
        num_beams=4,
        early_stopping=True
    )


# ãƒšãƒ¼ã‚¸è¨­å®š
st.set_page_config(
    page_title="è¨˜äº‹è¦ç´„ï¼ˆãƒ‡ãƒ¢ï¼‰",
    page_icon="ğŸ“š",
    layout="centered",
)

# ã‚¢ãƒ—ãƒªã®ã‚¿ã‚¤ãƒˆãƒ«
st.title("è¨˜äº‹è¦ç´„ï¼ˆãƒ‡ãƒ¢ï¼‰")
st.subheader("å…¥åŠ›ã‚’å…ƒã«è¦ç´„ã‚’ç”Ÿæˆã—ã¾ã™")

# å…¥åŠ›ãƒ•ã‚©ãƒ¼ãƒ 
with st.form("input_form"):
    # novel_title = st.text_input("å°èª¬ã®ã‚¿ã‚¤ãƒˆãƒ«", placeholder="ä¾‹ï¼šäººé–“å¤±æ ¼")
    input_text = st.text_area("è¨˜äº‹å†…å®¹", height=200, placeholder="ä¾‹ï¼šä¸»äººå…¬ã®è‘‰è”µã¯è‡ªåˆ†ã‚’ã€Œäººé–“å¤±æ ¼ã€ã ã¨è€ƒãˆã¦ã„ã‚‹...")
    submit_button = st.form_submit_button("ç”Ÿæˆ")

# é€ä¿¡ãƒœã‚¿ãƒ³ãŒæŠ¼ã•ã‚ŒãŸã‚‰çµæœã‚’è¡¨ç¤º
if submit_button:
    # st.markdown("## å…¥åŠ›å†…å®¹")
    # # st.write(f"**ã‚¿ã‚¤ãƒˆãƒ«:** {novel_title}")
    # st.write("**ã‚ã‚‰ã™ã˜ã‚„æ„Ÿæƒ³ãƒ¡ãƒ¢:**")
    # st.write(summary)

    # st.markdown("---")

    summary = summarize_article(input_text)

    st.markdown("## ç”Ÿæˆã•ã‚ŒãŸæ„Ÿæƒ³è¨˜äº‹ï¼ˆãƒ‡ãƒ¢ï¼‰")
    st.info(f"""
    {summary["summary_text"][0]}
    """)

# ãƒ•ãƒƒã‚¿ãƒ¼
st.markdown("---")
st.caption("Powered by Streamlit & Hugging Face")
